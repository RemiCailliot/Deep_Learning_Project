{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm_by_epoch.ipynb",
      "provenance": [],
      "mount_file_id": "1fs1fdt8tijp_fcNZv1KaPROr4kbbT5aG",
      "authorship_tag": "ABX9TyOFd0YYQ66ujEM+CCv1twfO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RemiCailliot/Deep_Learning_Project/blob/main/lstm_by_epoch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yx-nSEVi47bx"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename = \"/content/drive/MyDrive/Colab files/001ssb.txt\"\n",
        "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
        "text = raw_text.lower()"
      ],
      "metadata": {
        "id": "jVRErW9I6Rh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IplcDlFA5NCX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c59f36a3-6b28-4975-ad7b-d57f209eed55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corpus length: 1607894\n",
            "Total chars: 52\n",
            "Number of sequences: 535952\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        }
      ],
      "source": [
        "text = text.replace(\"\\n\", \" \")  # We remove newlines chars for nicer display\n",
        "print(\"Corpus length:\", len(text))\n",
        "\n",
        "chars = sorted(list(set(text)))\n",
        "print(\"Total chars:\", len(chars))\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "# cut the text in semi-redundant sequences of maxlen characters\n",
        "maxlen = 40\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "    sentences.append(text[i : i + maxlen])\n",
        "    next_chars.append(text[i + maxlen])\n",
        "print(\"Number of sequences:\", len(sentences))\n",
        "\n",
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(maxlen, len(chars))),\n",
        "        layers.LSTM(128),\n",
        "        layers.Dense(len(chars), activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "optimizer = keras.optimizers.RMSprop(learning_rate=0.01)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer)"
      ],
      "metadata": {
        "id": "J7RLwTxT5Tmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype(\"float64\")\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "\n"
      ],
      "metadata": {
        "id": "13Ql2k0Y5Yij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "batch_size = 128\n",
        "\n",
        "\n",
        "model.fit(x, y, batch_size=batch_size, epochs=epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxQmv55h-P63",
        "outputId": "10066f46-edda-4dac-d896-005d722b31e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "4188/4188 [==============================] - 59s 13ms/step - loss: 1.6962\n",
            "Epoch 2/20\n",
            "4188/4188 [==============================] - 56s 13ms/step - loss: 1.4794\n",
            "Epoch 3/20\n",
            "4188/4188 [==============================] - 55s 13ms/step - loss: 1.4303\n",
            "Epoch 4/20\n",
            "4188/4188 [==============================] - 55s 13ms/step - loss: 1.4015\n",
            "Epoch 5/20\n",
            "4188/4188 [==============================] - 56s 13ms/step - loss: 1.3840\n",
            "Epoch 6/20\n",
            "4188/4188 [==============================] - 57s 14ms/step - loss: 1.3708\n",
            "Epoch 7/20\n",
            "4188/4188 [==============================] - 57s 14ms/step - loss: 1.3625\n",
            "Epoch 8/20\n",
            "4188/4188 [==============================] - 57s 13ms/step - loss: 1.3545\n",
            "Epoch 9/20\n",
            "4188/4188 [==============================] - 57s 14ms/step - loss: 1.3469\n",
            "Epoch 10/20\n",
            "4188/4188 [==============================] - 56s 13ms/step - loss: 1.3423\n",
            "Epoch 11/20\n",
            "4188/4188 [==============================] - 56s 13ms/step - loss: 1.3374\n",
            "Epoch 12/20\n",
            "4188/4188 [==============================] - 56s 13ms/step - loss: 1.3344\n",
            "Epoch 13/20\n",
            "4188/4188 [==============================] - 56s 13ms/step - loss: 1.3323\n",
            "Epoch 14/20\n",
            "4188/4188 [==============================] - 55s 13ms/step - loss: 1.3285\n",
            "Epoch 15/20\n",
            "4188/4188 [==============================] - 56s 13ms/step - loss: 1.3250\n",
            "Epoch 16/20\n",
            "4188/4188 [==============================] - 56s 13ms/step - loss: 1.3238\n",
            "Epoch 17/20\n",
            "4188/4188 [==============================] - 56s 13ms/step - loss: 1.3219\n",
            "Epoch 18/20\n",
            "4188/4188 [==============================] - 56s 13ms/step - loss: 1.3206\n",
            "Epoch 19/20\n",
            "4188/4188 [==============================] - 56s 13ms/step - loss: 1.3192\n",
            "Epoch 20/20\n",
            "4188/4188 [==============================] - 55s 13ms/step - loss: 1.3156\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7d88af6a10>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print()\n",
        "print(\"Generating text after epoch: %d\" % epochs)\n",
        "start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "for diversity in [0.2, 0.5]:\n",
        "    print(\"...Diversity:\", diversity)\n",
        "\n",
        "    generated = \"\"\n",
        "    sentence = text[start_index : start_index + maxlen]\n",
        "    print('...Generating with seed: \"' + sentence + '\"')\n",
        "\n",
        "    for i in range(200):\n",
        "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "        for t, char in enumerate(sentence):\n",
        "            x_pred[0, t, char_indices[char]] = 1.0\n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "        next_index = sample(preds, diversity)\n",
        "        next_char = indices_char[next_index]\n",
        "        sentence = sentence[1:] + next_char\n",
        "        generated += next_char\n",
        "\n",
        "        #print(\"...Generated: \", generated)\n",
        "    print()\n",
        "    print(\"...Generated: \", generated)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQ19AQQq5bVv",
        "outputId": "fd3d59c5-7e1f-4f68-b966-c07fdbfaf051"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generating text after epoch: 20\n",
            "...Diversity: 0.2\n",
            "...Generating with seed: \" wedding ride.  his hair had never been \"\n",
            "\n",
            "...Generated:  a stark to the stark stark of the stark of the stark of the stark of the stark of the strong and stark and stark. the common said as the stark stark was the stark of the stark of the stark of the ston\n",
            "...Diversity: 0.5\n",
            "...Generating with seed: \" wedding ride.  his hair had never been \"\n",
            "\n",
            "...Generated:  hadow a horse and said  the wast and seemed with the second.  \"you can be a stup too men seemed to take the dirtsters and the armory, the first stark and light and made her wordion of the senting room\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate()"
      ],
      "metadata": {
        "id": "1K9Togw7MjnY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}