{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RemiCailliot/Deep_Learning_Project/blob/main/lstm_main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "MpraiVzVZsXF"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ssDQrxgoaL29"
      },
      "outputs": [],
      "source": [
        "\n",
        "# load ascii text and covert to lowercase\n",
        "filename = \"/content/drive/MyDrive/Colab files/001ssb.txt\"\n",
        "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
        "raw_text = raw_text.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "5CB_h012bPgj"
      },
      "outputs": [],
      "source": [
        "# create mapping of unique chars to integers\n",
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sV6jhUC7ayTs",
        "outputId": "1fc2b172-691d-461e-be74-7e5b5243bd0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Characters:  1607894\n",
            "Total Vocab:  53\n"
          ]
        }
      ],
      "source": [
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print(\"Total Characters: \", n_chars)\n",
        "print(\"Total Vocab: \", n_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5dLwQdXbACu",
        "outputId": "d0017c40-1430-4209-fc6e-e66334a171b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Patterns:  1607794\n"
          ]
        }
      ],
      "source": [
        "# prepare the dataset of input to output pairs encoded as integers\n",
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "\tseq_in = raw_text[i:i + seq_length]\n",
        "\tseq_out = raw_text[i + seq_length]\n",
        "\tdataX.append([char_to_int[char] for char in seq_in])\n",
        "\tdataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)\n",
        "print(\"Total Patterns: \", n_patterns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "XXN8kvgnb0ml"
      },
      "outputs": [],
      "source": [
        "# reshape X to be [samples, time steps, features]\n",
        "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "# normalize\n",
        "X = X / float(n_vocab)\n",
        "# one hot encode the output variable\n",
        "y = np_utils.to_categorical(dataY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "__JXHdJHb_sR"
      },
      "outputs": [],
      "source": [
        "# define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "UUbcKaUKcDNb"
      },
      "outputs": [],
      "source": [
        "# define the checkpoint\n",
        "\n",
        "filepath=\"/content/drive/MyDrive/Colab files/weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]\n",
        "#filename = \"/content/drive/MyDrive/Colab files/weights-improvement-05-1.7526.hdf5\"\n",
        "#model.load_weights(filename)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "x_train, xvalidate, x_test = np.split(X, [int(len(X)*0.8), int(len(X)*0.9)])\n",
        "y_train, yvalidate, y_test = np.split(y, [int(len(y)*0.8), int(len(y)*0.9)])"
      ],
      "metadata": {
        "id": "jX_olesaD_6K"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4qrw65gcFfV",
        "outputId": "0540271f-55f8-4620-da82-55634f28548f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "10049/10049 [==============================] - ETA: 0s - loss: 2.6410 - accuracy: 0.2505\n",
            "Epoch 1: loss improved from inf to 2.64101, saving model to /content/drive/MyDrive/Colab files/weights-improvement-01-2.6410.hdf5\n",
            "10049/10049 [==============================] - 380s 38ms/step - loss: 2.6410 - accuracy: 0.2505\n",
            "Epoch 2/5\n",
            "10049/10049 [==============================] - ETA: 0s - loss: 2.3624 - accuracy: 0.3171\n",
            "Epoch 2: loss improved from 2.64101 to 2.36244, saving model to /content/drive/MyDrive/Colab files/weights-improvement-02-2.3624.hdf5\n",
            "10049/10049 [==============================] - 374s 37ms/step - loss: 2.3624 - accuracy: 0.3171\n",
            "Epoch 3/5\n",
            "10048/10049 [============================>.] - ETA: 0s - loss: 2.2200 - accuracy: 0.3527\n",
            "Epoch 3: loss improved from 2.36244 to 2.21997, saving model to /content/drive/MyDrive/Colab files/weights-improvement-03-2.2200.hdf5\n",
            "10049/10049 [==============================] - 374s 37ms/step - loss: 2.2200 - accuracy: 0.3527\n",
            "Epoch 4/5\n",
            "10049/10049 [==============================] - ETA: 0s - loss: 2.1356 - accuracy: 0.3763\n",
            "Epoch 4: loss improved from 2.21997 to 2.13560, saving model to /content/drive/MyDrive/Colab files/weights-improvement-04-2.1356.hdf5\n",
            "10049/10049 [==============================] - 376s 37ms/step - loss: 2.1356 - accuracy: 0.3763\n",
            "Epoch 5/5\n",
            "10048/10049 [============================>.] - ETA: 0s - loss: 2.0734 - accuracy: 0.3939\n",
            "Epoch 5: loss improved from 2.13560 to 2.07337, saving model to /content/drive/MyDrive/Colab files/weights-improvement-05-2.0734.hdf5\n",
            "10049/10049 [==============================] - 379s 38ms/step - loss: 2.0734 - accuracy: 0.3939\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f26a6847910>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "model.fit(x_train, y_train, epochs=5, batch_size=128, callbacks=callbacks_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "BFhLy31TfTDe"
      },
      "outputs": [],
      "source": [
        "# load the network weights\n",
        "filename = \"/content/drive/MyDrive/Colab files/weights-improvement-05-1.7526.hdf5\"\n",
        "model.load_weights(filename)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "BBxE9gd2f7Pc"
      },
      "outputs": [],
      "source": [
        "int_to_char = dict((i, c) for i, c in enumerate(chars))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test,y_test,verbose=1)"
      ],
      "metadata": {
        "id": "s8qAEVwGFPM1",
        "outputId": "d3e5bfb7-e36d-4867-a5b3-d31d6857e426",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5025/5025 [==============================] - 76s 15ms/step - loss: 1.6384 - accuracy: 0.5129\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.638379454612732, 0.5129369497299194]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "9OM9qxGTgDDd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c918d8c5-b3ef-4984-a56a-8db43fb6a37e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed:\n",
            "\" emulous smile crept across his face. \n",
            "two serving wenches stood beneath the sign of the smoking log, \"\n",
            " she said the saie the sare and she had \n",
            "saee enong the sale the sase and she had so lent the saaeee of the sase and the sare and she had so \n",
            "hald the sale thet was so lent the saaeee of the saaeee and she had so lent the saaeee of the saven \n",
            "soall of the saven shater and the sare and she had so lent the saaeee of the saven shate of the saven \n",
            "saaele of the saven sarea wooden said the sarear sfe his hand and she had so lent the sase and \n",
            "she said the sase thi was the sare and she had so lent the saaeee of the sase and she had so lent the \n",
            "sooe then the sase and she had so lent the saaeee of the sase and the sare and she had so lent the \n",
            "sooe then the sase and she had so lent the saaeee of the sase and the sare and she had so lent the \n",
            "sooe then the sase and she had so lent the saaeee of the sase and the sare and she had so lent the \n",
            "sooe then the sase and she had so lent the saaeee of the sase and the sare and she had so lent the \n",
            "sooe then the sase and she had so lent the saaeee of th\n",
            "Done.\n"
          ]
        }
      ],
      "source": [
        "# pick a random seed\n",
        "# Load Larger LSTM network and generate text\n",
        "import sys\n",
        "start = numpy.random.randint(0, len(dataX)-1)\n",
        "pattern = dataX[start]\n",
        "print(\"Seed:\")\n",
        "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
        "# generate characters\n",
        "for i in range(1000):\n",
        "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "\tx = x / float(n_vocab)\n",
        "\tprediction = model.predict(x, verbose=0)\n",
        "\tindex = numpy.argmax(prediction)\n",
        "\tresult = int_to_char[index]\n",
        "\tseq_in = [int_to_char[value] for value in pattern]\n",
        "\tsys.stdout.write(result)\n",
        "\tpattern.append(index)\n",
        "\tpattern = pattern[1:len(pattern)]\n",
        "print(\"\\nDone.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "lstm_main.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/RemiCailliot/Deep_Learning_Project/blob/main/lstm_main.ipynb",
      "authorship_tag": "ABX9TyMIniQBg/qv8isX6idippIj",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}