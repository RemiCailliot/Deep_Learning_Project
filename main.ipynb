{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPk/IrsP4NwaP/cMAwFEM2+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RemiCailliot/Deep_Learning_Project/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-H5PaXOb-Ww8"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read, then decode for py2 compat.\n",
        "text = open('/content/drive/MyDrive/Colab files/001ssb.txt', 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "print(f'Length of text: {len(text)} characters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNHUtCtZ-oxE",
        "outputId": "9ffbe7f7-cbec-4c29-e874-cbd4d7c77ada"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 1628063 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Take a look at the first 250 characters in text\n",
        "print(text[:250])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2tDx7UkAdiT",
        "outputId": "eae13cc2-f692-4f34-b81b-fb9eba781519"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A Game Of Thrones \r\n",
            "Book One of A Song of Ice and Fire \r\n",
            "By George R. R. Martin \r\n",
            "PROLOGUE \r\n",
            "\"We should start back,\" Gared urged as the woods began to grow dark around them. \"The wildlings are \r\n",
            "dead.\" \r\n",
            "\"Do the dead frighten you?\" Ser Waymar Royce a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print(f'{len(vocab)} unique characters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_6Xs7ZAAikF",
        "outputId": "043be3a9-4bf0-42e1-c051-243490fe8414"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79 unique characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_texts = ['abcdefg', 'xyz']\n",
        "\n",
        "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
        "chars"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPggih7aAlbv",
        "outputId": "2f5cd673-b8b1-4b3d-c525-41ad1bfa84d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids_from_chars = tf.keras.layers.StringLookup(\n",
        "    vocabulary=list(vocab), mask_token=None)"
      ],
      "metadata": {
        "id": "G4vH79sTA_c5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ids = ids_from_chars(chars)\n",
        "ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KC3T30LeBBNp",
        "outputId": "aa644638-4bbe-4b78-8ff2-a1c6ba6fd1cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[53, 54, 55, 56, 57, 58, 59], [76, 77, 78]]>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars_from_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
      ],
      "metadata": {
        "id": "p3o5pBN3BDjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chars = chars_from_ids(ids)\n",
        "chars"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQ1aM6dMBE9g",
        "outputId": "dbebab85-4b98-4a72-b4ab-a8dbf001a574"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.strings.reduce_join(chars, axis=-1).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjg4ws3fBGgS",
        "outputId": "116741ff-8731-4425-b369-79effa548eb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'abcdefg', b'xyz'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def text_from_ids(ids):\n",
        "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ],
      "metadata": {
        "id": "tTyYGA0zBIJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "all_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHi6pgtUBKF9",
        "outputId": "2ea34daf-a704-47d4-9645-1fb7240559e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1628063,), dtype=int64, numpy=array([26,  3, 32, ...,  1,  2,  1])>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ],
      "metadata": {
        "id": "J2jxJptdBL4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ids in ids_dataset.take(10):\n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKMQtAuuBNas",
        "outputId": "7c322793-3d5f-4726-8861-8abf7d155b6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A\n",
            " \n",
            "G\n",
            "a\n",
            "m\n",
            "e\n",
            " \n",
            "O\n",
            "f\n",
            " \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 100\n",
        "examples_per_epoch = len(text)//(seq_length+1)"
      ],
      "metadata": {
        "id": "6K3f5SNxBQ6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(1):\n",
        "  print(chars_from_ids(seq))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvf1rmarBSuq",
        "outputId": "e34ad8de-e67a-46db-ccbe-5c72aa243db8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'A' b' ' b'G' b'a' b'm' b'e' b' ' b'O' b'f' b' ' b'T' b'h' b'r' b'o'\n",
            " b'n' b'e' b's' b' ' b'\\r' b'\\n' b'B' b'o' b'o' b'k' b' ' b'O' b'n' b'e'\n",
            " b' ' b'o' b'f' b' ' b'A' b' ' b'S' b'o' b'n' b'g' b' ' b'o' b'f' b' '\n",
            " b'I' b'c' b'e' b' ' b'a' b'n' b'd' b' ' b'F' b'i' b'r' b'e' b' ' b'\\r'\n",
            " b'\\n' b'B' b'y' b' ' b'G' b'e' b'o' b'r' b'g' b'e' b' ' b'R' b'.' b' '\n",
            " b'R' b'.' b' ' b'M' b'a' b'r' b't' b'i' b'n' b' ' b'\\r' b'\\n' b'P' b'R'\n",
            " b'O' b'L' b'O' b'G' b'U' b'E' b' ' b'\\r' b'\\n' b'\"' b'W' b'e' b' ' b's'\n",
            " b'h' b'o' b'u'], shape=(101,), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for seq in sequences.take(5):\n",
        "  print(text_from_ids(seq).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMh4LlJLBW6f",
        "outputId": "6a939514-6497-4876-fb0a-804793b60fdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'A Game Of Thrones \\r\\nBook One of A Song of Ice and Fire \\r\\nBy George R. R. Martin \\r\\nPROLOGUE \\r\\n\"We shou'\n",
            "b'ld start back,\" Gared urged as the woods began to grow dark around them. \"The wildlings are \\r\\ndead.\" '\n",
            "b'\\r\\n\"Do the dead frighten you?\" Ser Waymar Royce asked with just the hint of a smile. \\r\\nGared did not r'\n",
            "b'ise to the bait. He was an old man, past fifty, and he had seen the lordlings come and go. \\r\\n\"Dead is'\n",
            "b' dead,\" he said. \"We have no business with the dead.\" \\r\\n\"Are they dead?\" Royce asked softly. \"What pr'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text"
      ],
      "metadata": {
        "id": "5TVTiVMqBl-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_input_target(list(\"Tensorflow\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2uVwq8UBnSy",
        "outputId": "27948487-ce81-4057-b395-463fb58bcd53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = sequences.map(split_input_target)"
      ],
      "metadata": {
        "id": "DNyKUagqBosV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "    print(\"Target:\", text_from_ids(target_example).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfdjLQT8BqDo",
        "outputId": "63faf5d8-1059-4197-d3d7-74580f1d0b63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : b'A Game Of Thrones \\r\\nBook One of A Song of Ice and Fire \\r\\nBy George R. R. Martin \\r\\nPROLOGUE \\r\\n\"We sho'\n",
            "Target: b' Game Of Thrones \\r\\nBook One of A Song of Ice and Fire \\r\\nBy George R. R. Martin \\r\\nPROLOGUE \\r\\n\"We shou'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOmFxNwtBsLH",
        "outputId": "e2919fb5-1a60-4e9f-9d8d-0652adbe34c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ],
      "metadata": {
        "id": "eKFO4fo2BuRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x"
      ],
      "metadata": {
        "id": "3H3DJK9FBv_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyModel(\n",
        "    # Be sure the vocabulary size matches the `StringLookup` layers.\n",
        "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ],
      "metadata": {
        "id": "2Y9ghZGpBxyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5EuWQtvB08U",
        "outputId": "e02b09ab-e3bc-44b8-c877-bceedc86a538"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100, 80) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8C9w7YqB4Hb",
        "outputId": "2ca32154-54d1-4e3d-b3dc-d267c25a70ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     multiple                  20480     \n",
            "                                                                 \n",
            " gru_1 (GRU)                 multiple                  3938304   \n",
            "                                                                 \n",
            " dense_1 (Dense)             multiple                  82000     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,040,784\n",
            "Trainable params: 4,040,784\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()\n",
        "sampled_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukhnnscjB8pl",
        "outputId": "c92bb37d-615b-433f-f38b-777f7806668c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([30, 11, 41, 52,  9, 22, 19, 45,  9, 74, 18, 14, 48, 25, 44, 51, 76,\n",
              "       21, 39, 25, 57, 57, 74, 74, 26, 16, 49, 48, 24, 75, 63, 10, 10, 50,\n",
              "       58, 47, 53, 63, 39, 61, 74, 13, 10, 57, 15, 29, 25, 40, 71, 78, 28,\n",
              "       15, 37, 63, 60,  5, 22, 59, 32, 17, 61, 40, 74, 69, 43,  0, 53, 33,\n",
              "       69, 37, 37, 45, 67, 56, 73, 10, 53, 27,  9, 63, 54, 15, 42, 57, 27,\n",
              "       59, 79, 23, 42,  6, 47, 44, 44, 72, 13, 71, 39, 35, 64, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCX0anidCAcA",
        "outputId": "c495884a-72ed-4ea5-b905-e21f82b9cd90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:\n",
            " b' suddenly \\r\\nforgotten. \"What are you doing up there? Why aren\\'t you at the feast?\" \\r\\n\"Too hot, too n'\n",
            "\n",
            "Next Char Predictions:\n",
            " b'E-P`*96T*v51W?S]x8N?eevvA3XW;wk,,YfVakNiv0,e2D?OszC2Lkh\"9gG4iOvqR[UNK]aHqLLTodu,aB*kb2QeBg~:Q\\'VSSt0sNJlG'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ],
      "metadata": {
        "id": "MolPy33ODlvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", example_batch_mean_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHsaSdZbDpQR",
        "outputId": "d457c4fe-0573-44c9-a356-93480da54e15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction shape:  (64, 100, 80)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         tf.Tensor(4.3808165, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.exp(example_batch_mean_loss).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WC-fxo67Drox",
        "outputId": "ad178df0-4edf-4cfe-c2ec-cca62786262e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "79.903244"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "metadata": {
        "id": "-fEuYZO7DtI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "metadata": {
        "id": "UaggOjKmDvUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 20"
      ],
      "metadata": {
        "id": "AyfxOt71Dygn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btulLXTvDz2y",
        "outputId": "aa899780-384e-48cb-ebf5-373ba228489a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "251/251 [==============================] - 39s 140ms/step - loss: 2.4363\n",
            "Epoch 2/20\n",
            "251/251 [==============================] - 37s 139ms/step - loss: 1.7377\n",
            "Epoch 3/20\n",
            "251/251 [==============================] - 37s 140ms/step - loss: 1.4630\n",
            "Epoch 4/20\n",
            "251/251 [==============================] - 37s 139ms/step - loss: 1.3254\n",
            "Epoch 5/20\n",
            "251/251 [==============================] - 37s 140ms/step - loss: 1.2482\n",
            "Epoch 6/20\n",
            "251/251 [==============================] - 37s 139ms/step - loss: 1.1938\n",
            "Epoch 7/20\n",
            "251/251 [==============================] - 37s 139ms/step - loss: 1.1504\n",
            "Epoch 8/20\n",
            "251/251 [==============================] - 37s 139ms/step - loss: 1.1117\n",
            "Epoch 9/20\n",
            "251/251 [==============================] - 37s 139ms/step - loss: 1.0760\n",
            "Epoch 10/20\n",
            "251/251 [==============================] - 37s 139ms/step - loss: 1.0405\n",
            "Epoch 11/20\n",
            "251/251 [==============================] - 37s 139ms/step - loss: 1.0033\n",
            "Epoch 12/20\n",
            "251/251 [==============================] - 37s 139ms/step - loss: 0.9668\n",
            "Epoch 13/20\n",
            "251/251 [==============================] - 36s 138ms/step - loss: 0.9296\n",
            "Epoch 14/20\n",
            "251/251 [==============================] - 36s 138ms/step - loss: 0.8918\n",
            "Epoch 15/20\n",
            "251/251 [==============================] - 36s 138ms/step - loss: 0.8540\n",
            "Epoch 16/20\n",
            "251/251 [==============================] - 37s 139ms/step - loss: 0.8168\n",
            "Epoch 17/20\n",
            "251/251 [==============================] - 36s 138ms/step - loss: 0.7826\n",
            "Epoch 18/20\n",
            "251/251 [==============================] - 36s 138ms/step - loss: 0.7511\n",
            "Epoch 19/20\n",
            "251/251 [==============================] - 37s 139ms/step - loss: 0.7219\n",
            "Epoch 20/20\n",
            "251/251 [==============================] - 37s 140ms/step - loss: 0.6995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states"
      ],
      "metadata": {
        "id": "c0oFAqWAOpMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
      ],
      "metadata": {
        "id": "8fHErsntOsEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['Royce'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peeNSLJJOuBA",
        "outputId": "b61007b7-5250-44ed-a5db-b90e0e3df786"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Roycelle carrying the spearms of a gate, young Jon outragged chest and flocked \r\n",
            "upward at his father's eyes. Dragon had led him back to Robb from the Kingslayer rocks and turned it. Ser Waymar Royce fell from his teeth, his lower back weeping her face, she shouted before he approached. \r\n",
            "The wolf was there beside their voices and each weight of a mountain above them. \"Though what I can fear Lord Frey, you must. She yanked his seria to cragon for this and white. Catelyn was going to be a knight, armon, Catelyn thought, remembering. Sam shook his head. \r\n",
            "The humak of its razors were everywhere, and not even their wing. When she'd gone easher downgued, as Drogo writes. \"My son was easy to keep out into the wind, and they hunted those he would be good more talk. On every light who had been using than smiles and forest and leg a field of new stupid like that. Some of him \r\n",
            "weak in Winterfelled rider, and in his hands were covered with bright gold, the same grey cloaks drove the procession of Pe \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 6.37021803855896\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result, '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAJvM_JYOuw2",
        "outputId": "1b6d4602-4356-4526-fd0e-d077ad67c298"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'ROMEO: \\r\\nAnd anything Tyrion was too, her first voice surrounded, a sip of smoke and bowed. He would have told a Bearful lie than appectly. \\r\\nSer Kevan\\'s hair was beside the door. \"Father, don\\'t think I\\'d do out this toy, I promise you, no need you\\'d be so kind, child, not me. All you need a day here.\" \\r\\nJomar gave a reefer from the dirt and looked at him. \"My lord, will only trach or his name day,\" Tyrion told him as his sons settled darker stunged floor. \"Greatjon Uncler on you to serve you to cherish the steps of the poppy.\" \\r\\n\"The girl asked as to these two knights and fresh.\" \\r\\nSwinging approached. \"You have told that?\" \\r\\n\"Can\\'t you think?\" \\r\\n\"You told them, Petyr,\" she said, in arrors rippled onto its skun-shopped clothing of his. \"Alone. Yes, yes, my lord, no.\" She commanded his way down and urged her carefully snorting forward. \"Most lace as you find. I should have been best,\" she told him. \"The Ansalk will outrangerated his brother Jaime as well.\" Behind him, \\r\\nfollowing him, anywhe'\n",
            " b'ROMEO: \\r\\nSer Alliser Thorne announced, uncertain. \"The feast, Frogo and my guard to dress.\" \\r\\n\"Your brother is brought up straight, to protect me another mother, Jon Snow, no doubt the truth, perhaps . . . he won\\'t die on?\" \\r\\n\"You?\" Septa Mordane and her Redwynes were over strong from the kitchen and the sky was a blue on Daenerys without best. It swung her right at the head of the polished skulls, sweeting her body from the defenses and women and wordless for a deep grey, she knelt beside her. He chuckled at the bottom, mailed fiercely \\r\\nhad pushed his horsemat, that much, see that the rest for a few of the great bazaars than \\r\\nterrible to foster him free. The gropes of their mails could be to resume another silver and a hundred quarrelsome books from the slaves. I make the council tonight. Husile things that is the Kings in the Nort? There is bound where it felt wrong. He was not Lady Cohil, Chett thinking,\" Tyrion said, wondering. \\r\\nPage 26\\r\\n\\r\\nThe green belood them both hacked bored. \"Cry'\n",
            " b'ROMEO: \\r\\nAfter that, a world agreed. By the first watch the tighth letter and noble, and they see you here to go down, do you? How many wife . . . why do you think I want this way, does he? The least bit house about who should see how well dawn, yet he felt the cold and most of them, they would give you through, and they have the wit to do you aven. He couldn\\'t have given a sharp past the Free Cities now, I know what me \\r\\ntouch me. I was a raven larked back and wild, he thought, of course. One day she passed by the truth. And even the old gods will be use from least. The ciral instead \\r\\nto indigant? That flowed the clansmen uncertained. \"Is it out to the shadons into the sept.\" He took a sipple of the septa looked away, not impress clutched at all the last trught \\r\\nand shinting the cruel tower, burned again, like Mormont, writkening into her back was wide, his arms around them, his silks to give to three doors to his feet. They were almost on half moonlight. Lord Walder Frey in the Cense Arr'\n",
            " b'ROMEO: Ned touched her eyes butchered and trotted over all that. The tiny helm \\r\\nas exchange callused haming, but she had to usked his mother\\'s burdens. It had trained her again, and he saw every tree, through the smoldest sky with Tyrion tone and highborn. \"The black of grief. The third of the time they . . . they do not think it last night.\" \\r\\nHe heard and tunnels and black back was tight before herself in the shapeless silent voice, he donned the sadness in his horse. \"Your sister is ready. They lived in the dark. Robert\\'s blood in the Night\\'s Watch. If \\r\\nthe septa was intended, too see he\\'d be different. He\\'s eyrie men, but the shirts will not have it all? Lord Frey in trueborn sweet villages along the king\\'s \\r\\njustices. When the Kingslayer, \" Sansa realized with fresh-blanket, and Ser \\r\\nRobar\\'s laughter fingered the fire beside his eyes with Jack from his stance, and crossbled. Jeyne Poole peered at him with submerned smoke. \\r\\nA large cautioned him were dry and complement. That, he had '\n",
            " b'ROMEO: \\r\\nThe common room, as the woman passed beneath the melee. When he carried him with as wing and wisps of edgent. Her long auburn hair was leading their sconces in his squire. Us anop after all. It \\r\\npassed a ruler with jointly for such devised. Since hesitated beyond the room. \"Look. It\\'s you, but I told her to hear you.\" \\r\\nLittlefinger shrieked. \"Mightly that if he\\'s very crying, the City Watch is my father\\'s.\" \\r\\n\"Put the pale immense brothels?\" Varys told him. \"You are a stupid sword unless for his teeth. Qotho-\" \\r\\n\"How many men of keek him counsel?\" His father\\'s voice carce darkeh. He had been six, and that was the only potwer half-blinding at the small crescent moleskingess. I trisped the Targaryen hostes!\" And his friendscreat lovels telling a chill in hand, young \\r\\nsilent. \\r\\nThe river, rich windows, his stick. \"Common tradelens and two men attacked a meaty than to him . . . there\\'s black and woodly for a long moment, but otherwise . . . it was the steep running, but he knew what '], shape=(5,), dtype=string) \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 6.10807466506958\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.saved_model.save(one_step_model, 'one_step')\n",
        "one_step_reloaded = tf.saved_model.load('one_step')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRNu5y5lO22R",
        "outputId": "5496ecb4-4632-4a26-8260-1dbcadc65737"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x7f6c068e2c90>, because it is not built.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_1_layer_call_fn, gru_cell_1_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: one_step/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: one_step/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(100):\n",
        "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iahCUpuO4ju",
        "outputId": "03a7fa9c-e4ed-4eb8-cd1c-4c1ad9668bd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROMEO: Her brother was miles from Mob', half-meanund it kings were all wise, Catelyn, Tyrion says we shoul\n"
          ]
        }
      ]
    }
  ]
}